{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrJhM5ZG3RhKiFwql/SVqZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ac8eca0616247e496d9ae1e0625a586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4ab1a7706c348eeae9f140a4c8022c0",
              "IPY_MODEL_1eeb84d0ccc943419550e9678167d241",
              "IPY_MODEL_7f77d8cff1104eefa14ed7ec34626bc8"
            ],
            "layout": "IPY_MODEL_9338850b01474f57aa8518b5249686ff"
          }
        },
        "d4ab1a7706c348eeae9f140a4c8022c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_861b319e15cd40bf80879a2c2f07f175",
            "placeholder": "​",
            "style": "IPY_MODEL_a8f9ae5c8d484d9a9370c06b0b974e17",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1eeb84d0ccc943419550e9678167d241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44bb7c39822646c88acf80e271eda56f",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_642466cd195b4dba8b661a38a4f76460",
            "value": 8
          }
        },
        "7f77d8cff1104eefa14ed7ec34626bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48ad13fc3dc34fbbb9f142b28a79938e",
            "placeholder": "​",
            "style": "IPY_MODEL_2ba162d5482e49ce8e534a12aafccf7f",
            "value": " 8/8 [00:46&lt;00:00,  8.20s/it]"
          }
        },
        "9338850b01474f57aa8518b5249686ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861b319e15cd40bf80879a2c2f07f175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f9ae5c8d484d9a9370c06b0b974e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44bb7c39822646c88acf80e271eda56f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642466cd195b4dba8b661a38a4f76460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48ad13fc3dc34fbbb9f142b28a79938e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba162d5482e49ce8e534a12aafccf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurav714/Simple-python-practice/blob/main/simple_llm_using_dataset_to_predict_which_type_of_dieses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIGnWuJnoe7W",
        "outputId": "c04493a1-1afc-4423-9e57-5ea77a2c699b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install safetensors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSUj6ZwHwHnT",
        "outputId": "2cf73bfe-52f5-4f46-d61e-354661c4c553"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        "    offload_folder=\"./offload\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396,
          "referenced_widgets": [
            "9ac8eca0616247e496d9ae1e0625a586",
            "d4ab1a7706c348eeae9f140a4c8022c0",
            "1eeb84d0ccc943419550e9678167d241",
            "7f77d8cff1104eefa14ed7ec34626bc8",
            "9338850b01474f57aa8518b5249686ff",
            "861b319e15cd40bf80879a2c2f07f175",
            "a8f9ae5c8d484d9a9370c06b0b974e17",
            "44bb7c39822646c88acf80e271eda56f",
            "642466cd195b4dba8b661a38a4f76460",
            "48ad13fc3dc34fbbb9f142b28a79938e",
            "2ba162d5482e49ce8e534a12aafccf7f"
          ]
        },
        "id": "hw6GuFi3wJVk",
        "outputId": "5add98a4-7499-454b-899c-010b0bd927a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository OpenAssistant/falcon-7b-sft-top1 contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/OpenAssistant/falcon-7b-sft-top1 .\n",
            " You can inspect the repository content at https://hf.co/OpenAssistant/falcon-7b-sft-top1.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RWForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ac8eca0616247e496d9ae1e0625a586"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "RWForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "RWForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 STEP 1: Install required packages\n",
        "!pip install -qU openai kagglehub pandas\n",
        "\n",
        "# ✅ STEP 2: Set NVIDIA API Key for NIM endpoint\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"🔐 Enter your NVIDIA API Key:\")\n",
        "\n",
        "# ✅ STEP 3: Load NVIDIA-hosted GPT-OSS-20B via OpenAI SDK\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key=os.environ[\"NVIDIA_API_KEY\"]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOOmcPf_xptQ",
        "outputId": "4a3e9852-c003-4da8-da63-71e70833444b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔐 Enter your NVIDIA API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ STEP 4: Download disease-symptom dataset from Kaggle\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"itachi9604/disease-symptom-description-dataset\")\n",
        "print(\"✅ Dataset downloaded to:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMeA06tkx1LO",
        "outputId": "96bfe9d9-2553-4ef9-d6a0-8760cd32ce94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset downloaded to: /kaggle/input/disease-symptom-description-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install kagglehub if not already\n",
        "!pip install -q kagglehub\n",
        "\n",
        "# STEP 2: Download the dataset from Kaggle\n",
        "import kagglehub\n",
        "\n",
        "# Download and get the path to the dataset\n",
        "path = kagglehub.dataset_download(\"itachi9604/disease-symptom-description-dataset\")\n",
        "print(\"✅ Dataset downloaded to:\", path)\n",
        "\n",
        "# STEP 3: Load the CSV files using the correct filenames\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Check files in the dataset path\n",
        "print(\"📂 Files in dataset folder:\", os.listdir(path))\n",
        "\n",
        "# Read the CSV files (verify filenames if needed)\n",
        "df_dataset = pd.read_csv(os.path.join(path, \"dataset.csv\"))\n",
        "df_descriptions = pd.read_csv(os.path.join(path, \"symptom_Description.csv\"))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n3oYmM7yd4M",
        "outputId": "9b3fa32b-d904-4f47-a794-4bb65d9f1027"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset downloaded to: /kaggle/input/disease-symptom-description-dataset\n",
            "📂 Files in dataset folder: ['symptom_Description.csv', 'Symptom-severity.csv', 'symptom_precaution.csv', 'dataset.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 🚀 STEP 1: Install necessary packages\n",
        "!pip install -qU openai kagglehub pandas\n",
        "\n",
        "# 🚀 STEP 2: Set your NVIDIA API Key securely\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Use getpass to securely input the NVIDIA API Key\n",
        "os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"🔐 Enter your NVIDIA API Key:\")\n",
        "\n",
        "# 🚀 STEP 3: Initialize OpenAI client for NVIDIA GPT-OSS-20B\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
        "    api_key=os.environ[\"NVIDIA_API_KEY\"]\n",
        ")\n",
        "\n",
        "# 🚀 STEP 4: Download dataset from Kaggle using kagglehub\n",
        "import kagglehub\n",
        "\n",
        "# This will download the dataset to ~/.kagglehub/datasets/itachi9604/disease-symptom-description-dataset/\n",
        "dataset_path = kagglehub.dataset_download(\"itachi9604/disease-symptom-description-dataset\")\n",
        "print(\"✅ Dataset downloaded to:\", dataset_path)\n",
        "\n",
        "# OPTIONAL: Explore the dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Get CSV files in the dataset path\n",
        "csv_files = [f for f in os.listdir(dataset_path) if f.endswith('.csv')]\n",
        "\n",
        "# Load the first CSV file (you can change this if needed)\n",
        "df = pd.read_csv(os.path.join(dataset_path, csv_files[0]))\n",
        "print(\"✅ Loaded CSV:\", csv_files[0])\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnJIKc8d7PKj",
        "outputId": "f58bb7e8-70c2-474b-f2fa-54d84e6e8602"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔐 Enter your NVIDIA API Key:··········\n",
            "✅ Dataset downloaded to: /kaggle/input/disease-symptom-description-dataset\n",
            "✅ Loaded CSV: symptom_Description.csv\n",
            "          Disease                                        Description\n",
            "0   Drug Reaction  An adverse drug reaction (ADR) is an injury ca...\n",
            "1         Malaria  An infectious disease caused by protozoan para...\n",
            "2         Allergy  An allergy is an immune system response to a f...\n",
            "3  Hypothyroidism  Hypothyroidism, also called underactive thyroi...\n",
            "4       Psoriasis  Psoriasis is a common skin disorder that forms...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_gpt(prompt, model=\"gpt-oss-20b\", max_tokens=300, temp=0.7):\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful medical assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=temp,\n",
        "            max_tokens=max_tokens,\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error:\", e)\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "7vSqLmB57y1g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = ask_gpt(\"\"\"\n",
        "The patient is experiencing the following symptoms:\n",
        "- muscle_pain\n",
        "- fatigue\n",
        "- high_fever\n",
        "- skin_rash\n",
        "\n",
        "Which disease might this indicate? Explain why.\n",
        "\"\"\")\n",
        "print(\"🧠 GPT-OSS-20B Output:\\n\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__yVi9ef70jl",
        "outputId": "b1eaef0d-81c7-4de1-cf66-33365d6e345d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error: 404 page not found\n",
            "🧠 GPT-OSS-20B Output:\n",
            " None\n"
          ]
        }
      ]
    }
  ]
}